---
title: "SMPE Project"
author: "Insaf Boukrouh & Othmane Nahyl"
date: "30 d√©cembre 2017"
output: 
  html_document: 
    fig_height: 10
    fig_width: 10
    highlight: tango
---
## Loading and cleaning the datasets
```{r, message=F, warning=F, cache=T}
library(plyr)
library(doParallel)
library(ggplot2)
library(grid)
library(gridExtra)

# Remove lines with NA values in the columns that we're interested in
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}

# Register parallel backend in order to load files in parallel
nodes <- detectCores()
cl <- makeCluster(nodes)
registerDoParallel(cl)

# Load the csv files and keep certain columns
cities_data = ldply(list.files(path="../usa-data/",pattern="csv",full.names=TRUE),.parallel = TRUE,function(filename) {
  # Columns to keep
    keeps <- c("id","host_id","host_response_time","host_response_rate","host_acceptance_rate","host_total_listings_count","zipcode","country_code","property_type","room_type","accommodates","bathrooms","bedrooms","beds","bed_type","square_feet","price","security_deposit","cleaning_fee","extra_people","minimum_nights","maximum_nights","number_of_reviews","review_scores_rating","review_scores_accuracy","review_scores_cleanliness","review_scores_checkin","review_scores_communication","review_scores_location","review_scores_value","instant_bookable","cancellation_policy","host_since","calendar_last_scraped","city","state")
    city_data = read.csv(filename)
    city_data <- city_data[keeps]
    
    return(city_data)
})

stopCluster(cl)
```

## Cleaning the datasets
```{r, message=F, warning=F, cache=T}
# Convert host_response_rate from factors to numeric values
cities_data$host_response_rate <- as.numeric(gsub("%", "", as.character(cities_data$host_response_rate)))/100

# Convert host_acceptance_rate from factors to numeric values
cities_data$host_acceptance_rate <- as.numeric(gsub("%", "", as.character(cities_data$host_acceptance_rate)))/100

# Convert price from factors to numeric values
cities_data$price <- as.double(substring(gsub(",", "", as.character(cities_data$price)),2))

# Convert security_deposit from factors to numeric values
cities_data$security_deposit <- as.double(substring(gsub(",", "", as.character(cities_data$security_deposit)),2))
cities_data$security_deposit[is.na(cities_data$security_deposit)] <- 0

# Convert cleaning_fee from factors to numeric values
cities_data$cleaning_fee <- as.double(substring(gsub(",", "", as.character(cities_data$cleaning_fee)),2))
cities_data$cleaning_fee[is.na(cities_data$cleaning_fee)] <- 0

# Convert extra_people from factors to numeric values
cities_data$extra_people <- as.double(substring(gsub(",", "", as.character(cities_data$extra_people)),2))
cities_data$extra_people[is.na(cities_data$extra_people)] <- 0
```

## Different plots
```{r, message=F, warning=F}
summary(cities_data)
```

## Price plots according to different parameters
```{r, message=F, warning=F, cache=T}
cities_data_without_null_host_response_time <-subset(cities_data,host_response_time != "N/A" & host_response_time != "")
ggplot(data = cities_data_without_null_host_response_time, aes(x = host_response_time, y = price,color=host_response_time)) + geom_boxplot() +geom_jitter(position=position_jitter(0.3),size=0.1)+ theme(axis.text.x = element_text(angle = 90, hjust = 1)) 

ggplot(data = cities_data, aes(x = host_response_rate, y = price, color=host_response_rate)) + geom_point(size=0.1)

ggplot(data = cities_data, aes(x = host_total_listings_count, y = price, color=host_total_listings_count)) +geom_point(size=0.1) 

cities_data_without_null_property_type <-subset(cities_data,property_type != "N/A" & property_type != "")
ggplot(data = cities_data_without_null_property_type, aes(x = property_type, y = price,color=property_type))+ geom_boxplot() +geom_jitter(position=position_jitter(0.3),size=0.1)+ theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggplot(data = cities_data, aes(x = room_type, y = price,color=room_type))+ geom_boxplot() +geom_jitter(position=position_jitter(0.3),size=0.1) + theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggplot(data = cities_data, aes(x = accommodates, y = price,color=accommodates)) +geom_jitter(position=position_jitter(0.3),size=0.1) 

ggplot(data = cities_data, aes(x = bathrooms, y = price, color=bathrooms)) +geom_jitter(width = 0.1,height = 0.2,size=0.1) 

ggplot(data = cities_data, aes(x = bedrooms, y = price,color=bedrooms)) +geom_jitter(position=position_jitter(0.3),size=0.1) 

ggplot(data = cities_data, aes(x = beds, y = price,color=beds)) +geom_jitter(position=position_jitter(0.3),size=0.1)

ggplot(data = cities_data, aes(x = bed_type, y = price,color=bed_type))+ geom_boxplot() +geom_jitter(position=position_jitter(0.3),size=0.1)

ggplot(data = cities_data, aes(x = square_feet, y = price,color=square_feet)) +geom_point(size=0.1)

ggplot(data = cities_data, aes(x = minimum_nights, y = price,color=minimum_nights))  +geom_point(size=0.1)

ggplot(data = cities_data, aes(x = maximum_nights, y = price,color=maximum_nights)) +geom_point(size=0.1)

ggplot(data = cities_data, aes(x = instant_bookable, y = price,color=instant_bookable))+ geom_boxplot() +geom_jitter(position=position_jitter(0.3),size=0.1)

ggplot(data = cities_data, aes(x = cancellation_policy, y = price,color=cancellation_policy))+ geom_boxplot() +geom_jitter(position=position_jitter(0.3),size=0.1) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
The plots show no correlations between the price and the majority of the parameters: the host response time, the host response rate, the host total listings count, the number of accommodates, the number of bathrooms, the number of bedrooms, the number of beds, the number of minimum and maximum nights (most of the listings don't have restrictions about these two parameters), whether the listing is instant bookable or not, and the cancellation policy (we can only see that the prices are slightly more expensive for the listings that have a strict cancellation policy).

For the square_feet, the great majority of the listings don't have this information. Thus, we can't conclude anything regarding it.

There are possible correlations between the price and:
- The property type: the prices are very expensive for some types like the earth houses and the tree houses.
- The room type: the entire homes are generally more expensive than the other types, and the shared rooms are the cheapest ones.
- The bed type: beds other than real ones are generally cheaper, but we have a big variability for the real beds.

In terms of variability, it's high for most of the boxplots. We also see that most of them are skewed towards the bottom, which indicates that the higher the prices are, the more spread out they are.

## Miscellaneous
```{r}
# function: removing lines with NA values in specific columns
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}

# function: removing spaces
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
```

### Incomes
```{r, message=F, warning=F, cache=T}
# Clean
incomes_data <- completeFun(cities_data, c("price", "minimum_nights", "number_of_reviews", "host_since", "calendar_last_scraped"))

# Calculate the income for each listing
incomes_data$income <- incomes_data$number_of_reviews*incomes_data$minimum_nights*incomes_data$price

# This duration should be the same for listings having the same host 
incomes_data$duration <- abs(as.Date(as.character(incomes_data$calendar_last_scraped), format = "%Y-%m-%d") -
                          as.Date(as.character(incomes_data$host_since), format = "%Y-%m-%d"))/30

# Aggregate the income by host
incomes_data <- aggregate(
    cbind(incomes_data$income, incomes_data$duration),
    by = list(host_id = incomes_data$host_id),
    FUN = function(x) sum(x))

# Calculate the income per month
incomes_data$income_per_month = unlist(incomes_data['V1'])/unlist(incomes_data['V2'])

# Plot
ggplot(incomes_data, aes(x = income_per_month))+
  geom_histogram(color = "darkblue", fill = "lightblue", binwidth = 10)+
  labs(title = "Incomes in the USA", x = "Income per month", y = "Count")+
  coord_cartesian(xlim=c(0,500))
```
While a lot of people gain big amounts of money through AirBnB, most of them have an average income per month lower than 100 dollars.


### Type of listings
```{r, message=F, warning=F, cache=T}
# Get the room types and their percentages
room_types_counts <- table(cities_data$room_type)
room_types <- names(room_types_counts)
counts <- as.vector(room_types_counts)
percentages <- scales::percent(round(counts/sum(counts), 2))
room_types_percentages <- sprintf("%s (%s)", room_types, percentages)
room_types_counts_df <- data.frame(group = room_types, value = counts)

# Plot
pie <- ggplot(room_types_counts_df, aes(x = "", y = value, fill = room_types_percentages))+
  geom_bar(width = 1, stat = "identity")+
  coord_polar("y", start = 0)+
  scale_fill_brewer("Room Types", palette = "Dark2")+
  ggtitle("Type of listings")+
  ylab("")+
  xlab("")+
  labs(fill="")+
  theme(axis.ticks = element_blank(), panel.grid = element_blank(), axis.text = element_blank())+
  geom_text(aes(label = percentages), size = 5, position = position_stack(vjust = 0.5))
pie
```
Most of the listings are entire homes or appartments, while the shared rooms don't represent more than 3% of the entire listings.

### Evolution of new hosts over time
```{r, message=F, warning=F, cache=T}
# Clean
new_hosts_data <- completeFun(cities_data, c("host_since"))

# Calculate the number of new hosts for each year (except for 2017)
new_hosts_data$host_since <- as.Date(new_hosts_data$host_since, '%Y-%m-%d')
new_hosts_data <- new_hosts_data[new_hosts_data$host_since < as.Date("2017-01-01"),]
new_hosts_data <- new_hosts_data[order(as.Date(new_hosts_data$host_since, format="%Y-%m-%d")),]
new_hosts_data$host_since <- format(as.Date(new_hosts_data$host_since, "%Y-%m-%d"), format="%Y-%m")
new_hosts_data_table <- table(new_hosts_data$host_since)

# Plot
plot(as.Date(paste(format(names(new_hosts_data_table), format="%Y-%m"),"-01", sep="")), as.vector(new_hosts_data_table), type = "l", xlab = "Time", ylab = "Number of new hosts")
```
The number of new hosts was increasing since 2008. However, there was a decrease of this number in the last two years.

### Airbnb Prices
```{r, message=F, warning=F, cache=T}
# Clean
prices_per_state <- completeFun(cities_data, c("price","state"))
prices_per_state$state <- trim(prices_per_state$state)
prices_per_state <- subset(prices_per_state, prices_per_state$state != '')
prices_per_state$state[prices_per_state$state == 'New York'] <- 'NY'
prices_per_state$state[prices_per_state$state == 'ny'] <- 'NY'
prices_per_state$state[prices_per_state$state == 'Baja California'] <- 'CA'
prices_per_state$state[prices_per_state$state == 'secc Terrazas'] <- 'CA'
prices_per_state$state[prices_per_state$state == 'ca'] <- 'CA'
prices_per_state$state[prices_per_state$state == 'Ca'] <- 'CA'
prices_per_state$state[prices_per_state$state == 'wa'] <- 'WA'
prices_per_state$state[prices_per_state$state == 'il'] <- 'IL'
prices_per_state$state[prices_per_state$state == 'Il'] <- 'IL'

# Calculate the average price per city
average_prices_per_state <- aggregate(cbind(prices_per_state$price),
                  by = list(state = prices_per_state$state),
                  FUN = function(x) mean(x))

# Plot
ggplot(data = average_prices_per_state, aes(x = average_prices_per_state$state, y = average_prices_per_state$V1))+
    geom_bar(stat = "identity", fill = "steelblue", width = 0.7)+
    geom_text(aes(label = round(average_prices_per_state$V1, 2)), size=4)+
    coord_flip()+
    xlab("State")+
    ylab("Average Daily Price")+  
    theme_minimal()
```
The average daily price of listings in the state of Vermont is very high (650 dollars), while it's the lowest in Northern Mariana Islands (90 dollars). However, we can't conclude anything from the plot since the average prices alone aren't representative of the whole prices in every state.

To make a conclusion, we have to analyze the variability of the prices.

```{r}
ggplot(data = prices_per_state, aes(x = state, y = price, color = state)) + geom_boxplot() + geom_jitter(position=position_jitter(0.3),size=0.1) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
The plot shows that we have a high variability of the prices in the majority of the states. In Vermont and the Northern Mariana Islands, the boxplots are almost flat. 

```{r}
vt_data = prices_per_state[prices_per_state$state == 'VT',]
nrow(vt_data)
mp_data = prices_per_state[prices_per_state$state == 'MP',]
nrow(mp_data)
```
Indeed, we have only one record from each of these two states. Thus, the plot of average daily prices was misleading.

# Regression to explain the Ratings
```{r, message=F, warning=F, cache=T}
scores <- c("review_scores_rating","review_scores_accuracy","review_scores_cleanliness","review_scores_checkin","review_scores_communication","review_scores_location","review_scores_value")
scores_data <- cities_data[scores]
scores_data <- completeFun(scores_data, scores)

ggplot(data = scores_data, aes(x = review_scores_accuracy, y = review_scores_rating, color=review_scores_accuracy)) + geom_jitter(size = 0.1)

ggplot(data = scores_data, aes(x = review_scores_cleanliness, y = review_scores_rating, color=review_scores_cleanliness)) + geom_jitter(size = 0.1)

ggplot(data = scores_data, aes(x = review_scores_checkin, y = review_scores_rating, color=review_scores_checkin)) + geom_jitter(size = 0.1)

ggplot(data = scores_data, aes(x = review_scores_communication, y = review_scores_rating, color=review_scores_communication)) + geom_jitter(size = 0.1)

ggplot(data = scores_data, aes(x = review_scores_location, y = review_scores_rating, color=review_scores_location)) + geom_jitter(size = 0.1)

ggplot(data = scores_data, aes(x = review_scores_value, y = review_scores_rating, color=review_scores_value)) + geom_jitter(size = 0.1)
```
From the plots, we can see that most of the people who give the listings high ratings, give high scores for all the other types of scores. However, this is not enough to assume the existence of correlations between the global and the specific scores.

### Trying to fit a linear model to explain the Ratings
```{r, message=F, warning=F, cache=T}
# Linear model with all variables
r_reg1 <- lm(data=cities_data, review_scores_rating~review_scores_accuracy+review_scores_cleanliness+review_scores_checkin+review_scores_communication+review_scores_location+review_scores_value)
summary(r_reg1)
```
Our model has:

- A fairly good Adjusted R-squared value.

- A low residual standard error.

- Small standard errors of the coefficients of explanatory variables.


However, this is not enough to say that our linear model is good. To make sure of that, let's check whether the linear regression hypothesis hold or not.

```{r}
plot(r_reg1)
```
- The "Residuals vs Fitted" plot indicates if residuals have non-linear patterns. If the residuals are spread out around a horizontal line without distinct patterns, that means that we don't have non-linear relationships, which is not the case for our model since it seems that the residuals have some kind of structure.

- The "Normal Q-Q" plot shows if residuals are normally distributed. Our residuals are not well lined on the straight dashed line except in the middle of the plot, which is not quite good.

- The "Scale-Location" plot lets us check the assumption of equal variance (homoscedasticity). Our line is not horizontal with randomly spread points, thus, our residuals are not homoscedastic.

- The "Residuals vs Leverage" plot helps us find influential cases. In fact, even though data has outliers, they might not be influential to determine a regression line. In our plot, we can barely see Cook's distance lines because all cases are well inside of them. i.e: if we exclude the "52474" case for example, the changes in the slope coefficients won't be important.


To conclude, our linear model doesn't well explain the ratings.

# Regression to explain the Price
```{r}
# Candidates explanatory variables
variables <- c("host_response_time","host_response_rate","host_acceptance_rate","host_total_listings_count","zipcode","property_type","room_type","accommodates","bathrooms","bedrooms","beds","bed_type","square_feet","price","security_deposit","cleaning_fee","extra_people","minimum_nights","maximum_nights","number_of_reviews","instant_bookable","cancellation_policy")

# Clean the data
my_data <- cities_data
# my_data <- completeFun(cities_data, variables)
my_data$state <- trim(my_data$state)
my_data <- subset(my_data, my_data$state != '')
my_data$state[my_data$state == 'New York'] <- 'NY'
my_data$state[my_data$state == 'ny'] <- 'NY'
my_data$state[my_data$state == 'Baja California'] <- 'CA'
my_data$state[my_data$state == 'secc Terrazas'] <- 'CA'
my_data$state[my_data$state == 'ca'] <- 'CA'
my_data$state[my_data$state == 'Ca'] <- 'CA'
my_data$state[my_data$state == 'wa'] <- 'WA'
my_data$state[my_data$state == 'il'] <- 'IL'
my_data$state[my_data$state == 'Il'] <- 'IL'
```

### Trying to fit a linear model to explain the Price
```{r}
p_reg1 <- lm(data=my_data, price~host_acceptance_rate+host_total_listings_count+zipcode+property_type+room_type+accommodates+bathrooms+bedrooms+beds+bed_type+square_feet+security_deposit+cleaning_fee+extra_people+minimum_nights+maximum_nights+number_of_reviews+instant_bookable+cancellation_policy)
summary(p_reg1)
```
For this model, we have:

- A very good value of the adjusted R-squared.

- A high value of the residual standard error.

- Large standard errors for the model's coefficients.


Thus, this model is not good to explain the price. This was actually expected since, as we have seen previously, most of the explanatory variables we have here don't seem to have relations with the price, expect for 4 that can be possibly correlated for the price.

Let's see about that.

### Trying to fit a linear model with the most correlated variables
```{r}
p_reg2 <- lm(data=my_data, price~property_type+room_type+bed_type+cancellation_policy)
summary(p_reg2)
```
The model can't be worse. The adjusted R-squared is less than 0.1, the residual standard error is very high, and the model's coefficents's standard errors are very high as well.

Our hypothesis doesn't stand then.

Based on everyday's life, one can think that the price may be explained by the location, the square feet, and the number of bedrooms and bathrooms.

Let's try to check this.

### Trying to fit a linear model with some candidate variables
```{r}
# Linear regression with other variables
p_reg3 <- lm(data=my_data, price~zipcode+bedrooms+bathrooms+square_feet)
summary(p_reg3)
```
The Adjusted R-Squared is better than the previous model but is still very low, while the errors remain very high. 

We can also see that 141937 of the observations were deleted due to some missing information (very few of the listings have the square feet information), this, most probably, has a bad impact on our results.

This model is not good then.

We have tried many other linear models in order to explain the price, but all in vain. This may be because:

- There is no linear model to explain our data.

- Some information explaining the price could be missing (like the square feet for example).

- There could be some linear models that explain specific ranges of the price but not all our data (for example, the price may depend on the number of bedrooms for small appartments but this number becomes irrelevant once we start speaking about villas).

